{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regularizer; reload(regularizer)\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytransfer.learners.utils import calc_acc, Flatten\n",
    "\n",
    "class MNISTR_Encoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(MNISTR_Encoder, self).__init__()\n",
    "\n",
    "        row = input_shape[2]\n",
    "        self.latent_row = ((row - 4) - 4) / 2\n",
    "        self.latent_dim = 48 * self.latent_row**2\n",
    "        self.feature = nn.Sequential()\n",
    "        self.feature.add_module('f_conv1', nn.Conv2d(1, 32, kernel_size=5))\n",
    "        self.feature.add_module('f_relu1', nn.ReLU(True))\n",
    "        self.feature.add_module('f_conv2', nn.Conv2d(32, 48, kernel_size=5))\n",
    "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "        self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n",
    "        self.feature.add_module('f_flat', Flatten())\n",
    "        self.feature.add_module('f_fc1', nn.Linear(self.latent_dim, 100))\n",
    "        self.feature.add_module('f_relu1', nn.ReLU(True))  # FIXME\n",
    "        self.feature.add_module('f_fc2', nn.Linear(100, self.latent_dim))\n",
    "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        feature = self.feature(input_data)\n",
    "        return feature\n",
    "\n",
    "    def output_shape(self):\n",
    "        return (None, self.latent_dim)\n",
    "\n",
    "\n",
    "class MNISTR_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape, last_layer='log_softmax'):\n",
    "        super(MNISTR_Classifier, self).__init__()\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(input_shape[1], 100))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, num_classes))\n",
    "        if last_layer == 'log_softmax':\n",
    "            self.class_classifier.add_module('c_log_softmax', nn.LogSoftmax(dim=1))\n",
    "        elif last_layer == 'softmax':\n",
    "            self.class_classifier.add_module('c_softmax', nn.Softmax(dim=1))\n",
    "        elif last_layer == 'linear':\n",
    "            pass\n",
    "        else:\n",
    "            raise NameError()\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.class_classifier(input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytransfer.datasets.utils import prepare_datasets\n",
    "from pytransfer.datasets import MNISTR, OppG\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = prepare_datasets('M0','train', MNISTR, True)\n",
    "E = MNISTR_Encoder(train_dataset.get('input_shape'))\n",
    "M = MNISTR_Classifier(train_dataset.get('num_classes'), E.output_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "discriminator_config = {\n",
    "    'num_domains': 5, \n",
    "    'input_shape': E.output_shape(), \n",
    "    'hiddens': [800, 100]\n",
    "}\n",
    "K = 1\n",
    "alpha = 0.0\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data.DataLoader(train_dataset, batch_size=12800, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.__iter__().__next__()[2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f8024334dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create learner and add regularizer\n",
    "reload(regularizer)\n",
    "learner = regularizer.Learner(E, M).cuda()\n",
    "reg1 = regularizer.DANReguralizer(learner=learner, discriminator_config=discriminator_config, K=1).cuda()\n",
    "reg1.set_optimizer(optim.RMSprop(filter(lambda p: p.requires_grad, reg1.D.parameters()), lr=lr, alpha=0.9))\n",
    "learner.add_regularizer('d', reg1, alpha)\n",
    "\n",
    "learner.set_loader(train_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': 2.289016008377075, 0: -1.601906657218933}\n",
      "{'y': 2.2774336338043213, 0: -1.596584439277649}\n",
      "{'y': 2.296994209289551, 0: -1.609724998474121}\n",
      "{'y': 2.2771193981170654, 0: -1.6337519884109497}\n",
      "{'y': 2.2131567001342773, 0: -1.6508123874664307}\n",
      "{'y': 2.2394330501556396, 0: -1.590888500213623}\n",
      "{'y': 2.1626343727111816, 0: -1.6202645301818848}\n",
      "{'y': 2.1113083362579346, 0: -1.561773657798767}\n",
      "{'y': 2.146761417388916, 0: -1.5715571641921997}\n",
      "{'y': 1.93916654586792, 0: -1.6155956983566284}\n",
      "{'y': 1.9040277004241943, 0: -1.5821532011032104}\n",
      "{'y': 1.6744723320007324, 0: -1.639083981513977}\n",
      "{'y': 1.6856836080551147, 0: -1.56588613986969}\n",
      "{'y': 2.7197279930114746, 0: -1.6215894222259521}\n",
      "{'y': 1.741658329963684, 0: -1.5374647378921509}\n",
      "{'y': 1.7017606496810913, 0: -1.5392876863479614}\n",
      "{'y': 1.5270133018493652, 0: -1.6306371688842773}\n",
      "{'y': 1.4606997966766357, 0: -1.5209839344024658}\n",
      "{'y': 1.3277032375335693, 0: -1.5703285932540894}\n",
      "{'y': 1.2959564924240112, 0: -1.5330469608306885}\n",
      "{'y': 1.1748324632644653, 0: -1.6541005373001099}\n",
      "{'y': 1.0685348510742188, 0: -1.5774509906768799}\n",
      "{'y': 1.669785499572754, 0: -1.6758140325546265}\n",
      "{'y': 1.2014260292053223, 0: -1.5788248777389526}\n",
      "{'y': 1.0655858516693115, 0: -1.5114591121673584}\n",
      "{'y': 0.9972221255302429, 0: -1.5097379684448242}\n",
      "{'y': 0.9119920134544373, 0: -1.4965986013412476}\n",
      "{'y': 0.9210547804832458, 0: -1.5276128053665161}\n",
      "{'y': 1.0347906351089478, 0: -1.5393835306167603}\n",
      "{'y': 0.9694404602050781, 0: -1.7041531801223755}\n",
      "{'y': 0.9510685205459595, 0: -1.5793839693069458}\n",
      "{'y': 0.9328756332397461, 0: -1.4930315017700195}\n",
      "{'y': 0.7908931970596313, 0: -1.5328446626663208}\n",
      "{'y': 0.734978199005127, 0: -1.4593932628631592}\n",
      "{'y': 1.0025907754898071, 0: -1.4607815742492676}\n",
      "{'y': 1.1025757789611816, 0: -1.5168439149856567}\n",
      "{'y': 1.053127408027649, 0: -1.5734425783157349}\n",
      "{'y': 0.8338178992271423, 0: -1.4859671592712402}\n",
      "{'y': 0.6522330045700073, 0: -1.5115766525268555}\n",
      "{'y': 0.777722179889679, 0: -1.4665225744247437}\n",
      "{'y': 0.7826117873191833, 0: -1.5016639232635498}\n",
      "{'y': 0.627448320388794, 0: -1.4685906171798706}\n",
      "{'y': 0.6255399584770203, 0: -1.4210245609283447}\n",
      "{'y': 0.7537493109703064, 0: -1.4822745323181152}\n",
      "{'y': 0.7161760330200195, 0: -1.440901279449463}\n",
      "{'y': 0.8839831352233887, 0: -1.528437852859497}\n",
      "{'y': 0.8985752463340759, 0: -1.3811558485031128}\n",
      "{'y': 0.563530683517456, 0: -1.4839168787002563}\n",
      "{'y': 0.4731830060482025, 0: -1.4184962511062622}\n",
      "{'y': 0.6519054770469666, 0: -1.3771708011627197}\n",
      "{'y': 0.6816641688346863, 0: -1.4322458505630493}\n",
      "{'y': 0.6831625699996948, 0: -1.4962575435638428}\n",
      "{'y': 0.5890098214149475, 0: -1.4595229625701904}\n",
      "{'y': 0.8145163655281067, 0: -1.4489238262176514}\n",
      "{'y': 0.6364262104034424, 0: -1.3696602582931519}\n",
      "{'y': 0.5836200714111328, 0: -1.3112035989761353}\n",
      "{'y': 0.6291488409042358, 0: -1.4696699380874634}\n",
      "{'y': 0.604188084602356, 0: -1.3492116928100586}\n",
      "{'y': 0.6177282333374023, 0: -1.45851469039917}\n",
      "{'y': 0.50636887550354, 0: -1.3572723865509033}\n",
      "{'y': 0.3430344760417938, 0: -1.3906550407409668}\n",
      "{'y': 0.6140916347503662, 0: -1.4978418350219727}\n",
      "{'y': 0.43343088030815125, 0: -1.3846509456634521}\n",
      "{'y': 0.39393389225006104, 0: -1.436564326286316}\n",
      "{'y': 0.7226671576499939, 0: -1.3962575197219849}\n",
      "{'y': 0.656764030456543, 0: -1.3679934740066528}\n",
      "{'y': 0.3976752758026123, 0: -1.5166939496994019}\n",
      "{'y': 0.44814354181289673, 0: -1.4294123649597168}\n",
      "{'y': 0.3781088590621948, 0: -1.354123592376709}\n",
      "{'y': 0.6743042469024658, 0: -1.3561798334121704}\n",
      "{'y': 0.5968798398971558, 0: -1.477096676826477}\n",
      "{'y': 0.5534464120864868, 0: -1.4938844442367554}\n",
      "{'y': 0.4030188024044037, 0: -1.4110450744628906}\n",
      "{'y': 0.291349858045578, 0: -1.3997488021850586}\n",
      "{'y': 0.19461151957511902, 0: -1.3268804550170898}\n",
      "{'y': 0.5025991797447205, 0: -1.4451749324798584}\n",
      "{'y': 0.6552839279174805, 0: -1.361618161201477}\n",
      "{'y': 0.5180997848510742, 0: -1.4248409271240234}\n",
      "{'y': 0.36006495356559753, 0: -1.3118175268173218}\n",
      "{'y': 0.373034805059433, 0: -1.3301262855529785}\n",
      "{'y': 0.3700017035007477, 0: -1.359046220779419}\n",
      "{'y': 0.3521101474761963, 0: -1.421235203742981}\n",
      "{'y': 0.2601451575756073, 0: -1.3583285808563232}\n",
      "{'y': 0.23060515522956848, 0: -1.399181604385376}\n",
      "{'y': 0.2077587991952896, 0: -1.3462411165237427}\n",
      "{'y': 0.34263408184051514, 0: -1.4800143241882324}\n",
      "{'y': 0.36584216356277466, 0: -1.343204140663147}\n",
      "{'y': 0.3511579930782318, 0: -1.3967933654785156}\n",
      "{'y': 0.5724853873252869, 0: -1.3060060739517212}\n",
      "{'y': 0.34335100650787354, 0: -1.4258707761764526}\n",
      "{'y': 0.3027782440185547, 0: -1.310711145401001}\n",
      "{'y': 0.30494439601898193, 0: -1.344853401184082}\n",
      "{'y': 0.3295949101448059, 0: -1.4294430017471313}\n",
      "{'y': 0.3763708770275116, 0: -1.416656494140625}\n",
      "{'y': 0.39724603295326233, 0: -1.3772577047348022}\n",
      "{'y': 0.17560040950775146, 0: -1.4375970363616943}\n",
      "{'y': 0.34195777773857117, 0: -1.3643020391464233}\n",
      "{'y': 0.23210415244102478, 0: -1.3588660955429077}\n",
      "{'y': 0.44431930780410767, 0: -1.2982280254364014}\n",
      "{'y': 0.3729456067085266, 0: -1.2964147329330444}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "optimizer = optim.RMSprop(learner.parameters(), lr=lr, alpha=0.9)\n",
    "\n",
    "for i in range(100):\n",
    "    # update regularizers\n",
    "    learner.update_regularizers()\n",
    "    \n",
    "    # update learner's parameter\n",
    "    optimizer.zero_grad()\n",
    "    X, y, d = learner.get_batch()\n",
    "    loss = learner.loss(X, y, d)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(learner.losses(X, y, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = prepare_datasets('M0','train', MNISTR, True)\n",
    "E = MNISTR_Encoder(train_dataset.get('input_shape'))\n",
    "M = MNISTR_Classifier(train_dataset.get('num_classes'), E.output_shape())\n",
    "\n",
    "# create learner and add regularizer\n",
    "reload(regularizer)\n",
    "learner = regularizer.Learner(E, M).cuda()\n",
    "reg = regularizer.MultilabelDAN(learner=learner, discriminator_config=discriminator_config, K=1).cuda()\n",
    "reg.set_optimizer(optim.RMSprop(filter(lambda p: p.requires_grad, reg.D.parameters()), lr=lr, alpha=0.9))\n",
    "reg.set_loader(train_dataset, batch_size=128)\n",
    "learner.add_regularizer(reg, 0.0001)\n",
    "\n",
    "learner.set_loader(train_dataset, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': 2.2946529388427734, 0: 0.02334335446357727}\n",
      "{'y': 2.2772059440612793, 0: 1.053621530532837}\n",
      "{'y': 2.2896292209625244, 0: 0.31895527243614197}\n",
      "{'y': 2.2663674354553223, 0: 1.4587292671203613}\n",
      "{'y': 2.19545841217041, 0: 3.093266248703003}\n",
      "{'y': 2.2725424766540527, 0: 1.4379481077194214}\n",
      "{'y': 2.1823904514312744, 0: 2.775700807571411}\n",
      "{'y': 2.0532288551330566, 0: 2.4621403217315674}\n",
      "{'y': 2.044004440307617, 0: 3.972172737121582}\n",
      "{'y': 1.9444072246551514, 0: 8.164834976196289}\n",
      "{'y': 2.2076573371887207, 0: 0.7531702518463135}\n",
      "{'y': 2.011641263961792, 0: 3.9575748443603516}\n",
      "{'y': 1.8873004913330078, 0: 2.9986257553100586}\n",
      "{'y': 1.616126537322998, 0: 7.115194320678711}\n",
      "{'y': 1.5193337202072144, 0: 16.172590255737305}\n",
      "{'y': 1.8144150972366333, 0: 8.334641456604004}\n",
      "{'y': 1.6263090372085571, 0: 11.57399845123291}\n",
      "{'y': 1.3295502662658691, 0: 15.37466812133789}\n",
      "{'y': 1.4336886405944824, 0: 20.17281150817871}\n",
      "{'y': 1.3697203397750854, 0: 13.087739944458008}\n",
      "{'y': 1.3566240072250366, 0: 14.668131828308105}\n",
      "{'y': 1.3546041250228882, 0: 28.6221866607666}\n",
      "{'y': 1.1001548767089844, 0: 16.323495864868164}\n",
      "{'y': 1.11156165599823, 0: 11.483680725097656}\n",
      "{'y': 1.172479510307312, 0: 28.152320861816406}\n",
      "{'y': 1.1962590217590332, 0: 15.049957275390625}\n",
      "{'y': 1.10861074924469, 0: 15.631104469299316}\n",
      "{'y': 1.1337511539459229, 0: 16.192806243896484}\n",
      "{'y': 1.1447391510009766, 0: 16.75140953063965}\n",
      "{'y': 1.2168203592300415, 0: 14.585161209106445}\n",
      "{'y': 0.8483521342277527, 0: 15.576457977294922}\n",
      "{'y': 0.7558594346046448, 0: 23.320114135742188}\n",
      "{'y': 0.8591423034667969, 0: 19.498533248901367}\n",
      "{'y': 1.0910758972167969, 0: 19.847688674926758}\n",
      "{'y': 0.8672215938568115, 0: -0.14676904678344727}\n",
      "{'y': 0.8154545426368713, 0: 10.365804672241211}\n",
      "{'y': 0.71219801902771, 0: 17.581619262695312}\n",
      "{'y': 0.7097727656364441, 0: 14.459415435791016}\n",
      "{'y': 0.7932090759277344, 0: 10.709037780761719}\n",
      "{'y': 0.9414001107215881, 0: 9.182567596435547}\n",
      "{'y': 0.8876043558120728, 0: 5.252992153167725}\n",
      "{'y': 0.6687332987785339, 0: 4.754258155822754}\n",
      "{'y': 0.8669672012329102, 0: 7.275077819824219}\n",
      "{'y': 0.7186921834945679, 0: 22.440448760986328}\n",
      "{'y': 0.634776771068573, 0: 7.41914176940918}\n",
      "{'y': 0.651638925075531, 0: 25.450437545776367}\n",
      "{'y': 0.7495754957199097, 0: 20.49022102355957}\n",
      "{'y': 0.643180251121521, 0: 11.496620178222656}\n",
      "{'y': 0.5574731826782227, 0: 20.570331573486328}\n",
      "{'y': 0.782718300819397, 0: 37.78877639770508}\n",
      "{'y': 0.8113816380500793, 0: 25.037416458129883}\n",
      "{'y': 0.5385384559631348, 0: 28.031984329223633}\n",
      "{'y': 0.6200583577156067, 0: 26.472797393798828}\n",
      "{'y': 0.8606269359588623, 0: 16.360252380371094}\n",
      "{'y': 0.7067212462425232, 0: 9.814096450805664}\n",
      "{'y': 0.5052163004875183, 0: 19.02787971496582}\n",
      "{'y': 0.6331048607826233, 0: 9.704683303833008}\n",
      "{'y': 0.5940312147140503, 0: 17.88991355895996}\n",
      "{'y': 0.4597487151622772, 0: 14.966136932373047}\n",
      "{'y': 0.467049241065979, 0: 9.695955276489258}\n",
      "{'y': 0.42793935537338257, 0: 18.364267349243164}\n",
      "{'y': 0.45953723788261414, 0: 14.735244750976562}\n",
      "{'y': 0.31884488463401794, 0: 32.38624954223633}\n",
      "{'y': 0.6058318614959717, 0: 30.043420791625977}\n",
      "{'y': 0.6955643892288208, 0: 10.012205123901367}\n",
      "{'y': 0.5452300906181335, 0: 23.100072860717773}\n",
      "{'y': 0.3537798225879669, 0: 22.478960037231445}\n",
      "{'y': 0.43373918533325195, 0: 16.667104721069336}\n",
      "{'y': 0.3099103569984436, 0: 14.828224182128906}\n",
      "{'y': 0.3668142557144165, 0: 40.193294525146484}\n",
      "{'y': 0.5583599805831909, 0: 7.37484073638916}\n",
      "{'y': 0.4907952547073364, 0: 28.210790634155273}\n",
      "{'y': 0.48524466156959534, 0: 8.597661972045898}\n",
      "{'y': 0.33901914954185486, 0: 9.56253433227539}\n",
      "{'y': 0.3285205066204071, 0: 21.71396255493164}\n",
      "{'y': 0.7321513295173645, 0: 17.111778259277344}\n",
      "{'y': 0.7545993328094482, 0: 18.377307891845703}\n",
      "{'y': 0.49596452713012695, 0: 22.38957977294922}\n",
      "{'y': 0.4466502070426941, 0: 13.46780014038086}\n",
      "{'y': 0.33443304896354675, 0: 16.429515838623047}\n",
      "{'y': 0.35473760962486267, 0: 25.922714233398438}\n",
      "{'y': 0.3609398901462555, 0: 7.239396572113037}\n",
      "{'y': 0.3985166847705841, 0: 30.448318481445312}\n",
      "{'y': 0.30286481976509094, 0: 14.154484748840332}\n",
      "{'y': 0.26366037130355835, 0: 32.679290771484375}\n",
      "{'y': 0.42402350902557373, 0: 13.402460098266602}\n",
      "{'y': 0.24127116799354553, 0: 21.32649803161621}\n",
      "{'y': 0.36657822132110596, 0: 24.556781768798828}\n",
      "{'y': 0.5283069610595703, 0: 30.67510986328125}\n",
      "{'y': 0.7496312260627747, 0: 27.941160202026367}\n",
      "{'y': 0.3085164427757263, 0: 4.920645713806152}\n",
      "{'y': 0.2435903400182724, 0: 17.52794075012207}\n",
      "{'y': 0.3183709979057312, 0: 26.757081985473633}\n",
      "{'y': 0.22038228809833527, 0: 21.586349487304688}\n",
      "{'y': 0.3358646035194397, 0: 22.727529525756836}\n",
      "{'y': 0.4431980550289154, 0: 24.147598266601562}\n",
      "{'y': 0.3194950222969055, 0: 19.860477447509766}\n",
      "{'y': 0.27510082721710205, 0: 9.928245544433594}\n",
      "{'y': 0.23936833441257477, 0: 31.34384536743164}\n",
      "{'y': 0.21332061290740967, 0: 23.48373794555664}\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "optimizer = optim.RMSprop(learner.parameters(), lr=lr, alpha=0.9)\n",
    "\n",
    "for i in range(100):\n",
    "    # update regularizers\n",
    "    learner.update_regularizers()\n",
    "    \n",
    "    # update learner's parameter\n",
    "    optimizer.zero_grad()\n",
    "    X, y, d = learner.get_batch()\n",
    "    loss = learner.loss(X, y, d)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(learner.losses(X, y, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Adversares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f18600fe490>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(regularizer)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = prepare_datasets('M0','train', MNISTR, True)\n",
    "E = MNISTR_Encoder(train_dataset.get('input_shape'))\n",
    "M = MNISTR_Classifier(train_dataset.get('num_classes'), E.output_shape())\n",
    "learner = regularizer.Learner(E, M).cuda()\n",
    "\n",
    "# create learner and add regularizer\n",
    "discriminator_config = {\n",
    "    'num_domains': 5, \n",
    "    'input_shape': E.output_shape(), \n",
    "    'hiddens': [100], \n",
    "    'use_softmax': False, \n",
    "}\n",
    "reg = regularizer.MultipleDAN(learner=learner, num_discriminator=10, discriminator_config=discriminator_config, K=10, KL_weight=100).cuda()\n",
    "reg.set_optimizer(optim.RMSprop(filter(lambda p: p.requires_grad, reg.parameters()), lr=lr, alpha=0.9))\n",
    "learner.add_regularizer(\"d\", reg, 1.0)\n",
    "\n",
    "learner.set_loader(train_dataset, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('y-accuracy', 0.0965), ('y-f1macro', 0.017601459188326493), ('y-loss', 0.7378050613403321), ('d-accuracy', 0.2), ('d-f1macro', 0.06666666666666668), ('d-loss', 0.515129667520523)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/iwasawa/.pyenv/versions/anaconda2-4.0.0/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(learner.evaluate(data.DataLoader(train_dataset, batch_size=128), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('y-accuracy', 0.86975), ('y-f1macro', 0.8691818387545611), ('y-loss', 0.44405343011021614), ('d-accuracy', 0.2975), ('d-f1macro', 0.2657326657286933), ('d-loss', 1.5444549545645714)])\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "optimizer = optim.RMSprop(learner.parameters(), lr=lr, alpha=0.9)\n",
    "\n",
    "for i in range(10):\n",
    "    # update regularizers\n",
    "    learner.update_regularizers()\n",
    "    \n",
    "    # update learner's parameter\n",
    "    optimizer.zero_grad()\n",
    "    X, y, d = learner.get_batch()\n",
    "    loss = learner.loss(X, y, d)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(learner.evaluate(data.DataLoader(train_dataset, batch_size=128), None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        row = input_shape[2]\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_row = ((row - 4) - 4) / 2\n",
    "\n",
    "        self.feature = nn.Sequential()\n",
    "        self.feature.add_module('f_conv1', nn.Conv2d(input_shape[0], 32, kernel_size=5))\n",
    "        self.feature.add_module('f_relu1', nn.ReLU(True))\n",
    "        self.feature.add_module('f_conv2', nn.Conv2d(32, 48, kernel_size=5))\n",
    "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "        self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n",
    "        self.feature.add_module('flatten', Flatten())\n",
    "        self.feature.add_module('c_fc1', nn.Linear(48*self.latent_row**2, 100))\n",
    "        self.feature.add_module('c_relu1', nn.ReLU(True))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        feature = self.feature(input_data)\n",
    "        return feature\n",
    "    \n",
    "    def output_shape(self):\n",
    "        return (None, 100)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, input_shape):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(input_shape[1], 100))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(100, num_classes))\n",
    "        self.class_classifier.add_module('c_softmax', nn.LogSoftmax(dim=-1))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        return self.class_classifier(input_data)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = prepare_datasets('M0','train', MNISTR, True)\n",
    "E = Encoder(train_dataset.get('input_shape'))\n",
    "M = Classifier(train_dataset.get('num_classes'), E.output_shape())\n",
    "learner = regularizer.Learner(E, M).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_path = './../../similarity_confusion_training/pretrain_model/{}-{}-{}-E.pth'.format('mnistr', 'train', 'M0')\n",
    "M_path = './../../similarity_confusion_training/pretrain_model/{}-{}-{}-M.pth'.format('mnistr', 'train', 'M0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.E.load_state_dict(torch.load(E_path))\n",
    "learner.M.load_state_dict(torch.load(M_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('y-accuracy', 0.801),\n",
       "             ('y-f1macro', 0.8036341464847403),\n",
       "             ('y-loss', 1.1135996356606483)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "learner.evaluate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularizer import Discriminator\n",
    "from pytransfer.datasets.base import Subset\n",
    "from pytransfer.datasets.utils import get_joint_valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDivergence(nn.Module):\n",
    "    def __init__(self, learner, H_hiddens):\n",
    "        super(HDivergence, self).__init__()\n",
    "        self.learner = learner\n",
    "        H_config = {\n",
    "            'num_domains': 1, \n",
    "            'input_shape': learner.E.output_shape(),\n",
    "            'use_softmax': False, \n",
    "            'hiddens': H_hiddens\n",
    "        }\n",
    "        \n",
    "        self.H = Discriminator(**H_config)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.H.parameters()\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return nn.functional.sigmoid(self.H(z))\n",
    "    \n",
    "    def set_datasets(self, source, target, valid_split=0.0):\n",
    "        # reduce source dataset\n",
    "        indices = np.arange(len(source))\n",
    "        r = np.random.RandomState(1234)\n",
    "        r.shuffle(indices)\n",
    "        source = Subset(source, indices[:len(target)])\n",
    "        \n",
    "        # prepar validation data\n",
    "        if valid_split == 0.0:\n",
    "            source_train, source_test = source, source\n",
    "            target_train, target_test = target, target\n",
    "        else:\n",
    "            num_train = int(len(target) * (1-valid_split))\n",
    "            indices = np.arange(len(target))\n",
    "            r = np.random.RandomState(1234)\n",
    "            r.shuffle(indices)\n",
    "            self.source_train, self.source_test = Subset(source, indices[:num_train]), Subset(source, indices[num_train:])\n",
    "            self.target_train, self.target_test = Subset(target, indices[:num_train]), Subset(target, indices[num_train:])\n",
    "        return self.source_train, self.source_test, self.target_train, self.target_test\n",
    "        \n",
    "    def find_sup(self, source, target, batch_size=128, valid_split=0.5, num_iterations=1000, verbose=0):\n",
    "        criterion = torch.nn.BCELoss()\n",
    "        optimizer = optim.RMSprop(self.H.parameters(), lr=0.001, alpha=0.9)\n",
    "        source_train, source_test, target_train, target_test = reg.set_datasets(train_dataset, test_dataset, valid_split=valid_split)\n",
    "        \n",
    "        batch_size = batch_size/2\n",
    "        source_loader = data.DataLoader(source_train, batch_size=batch_size, shuffle=True)\n",
    "        target_loader = data.DataLoader(target_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        while True:\n",
    "            for (X_s, _, _), (X_t, _, _) in zip(source_loader, target_loader):\n",
    "                optimizer.zero_grad()\n",
    "                X_s = Variable(X_s.float()).cuda()\n",
    "                X_t = Variable(X_t.float()).cuda()\n",
    "                y_s = Variable(torch.FloatTensor(X_s.size(0), 1).fill_(1), requires_grad=False).cuda()\n",
    "                y_t = Variable(torch.FloatTensor(X_t.size(0), 1).fill_(0), requires_grad=False).cuda()\n",
    "                z_s = learner.E(X_s)\n",
    "                z_t = learner.E(X_t)\n",
    "\n",
    "                y_s_pred = reg(z_s)\n",
    "                y_t_pred = reg(z_t)\n",
    "                s_loss = criterion(y_s_pred, y_s)\n",
    "                t_loss = criterion(y_t_pred, y_t)\n",
    "                loss = s_loss + t_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                counter += 1\n",
    "                if (verbose > 0) and (counter % 100) == 0:\n",
    "                    print(reg.evaluate(source_train, target_train), reg.evaluate(source_test, target_test))\n",
    "            if counter >= num_iterations:\n",
    "                break;\n",
    "                \n",
    "    def evaluate(self, source, target, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = len(source)\n",
    "        source_loader = data.DataLoader(source, batch_size=batch_size, shuffle=True)\n",
    "        target_loader = data.DataLoader(target, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        h_divergence = 0\n",
    "        nb_batch = len(source_loader)\n",
    "        for (X_s, _, _), (X_t, _, _) in zip(source_loader, target_loader):\n",
    "            X_s = Variable(X_s.float()).cuda()\n",
    "            X_t = Variable(X_t.float()).cuda()\n",
    "            h_divergence += self._evaluate(X_s, X_t).data[0]\n",
    "        result = {}\n",
    "        result['divergence'] = h_divergence/nb_batch\n",
    "        return result\n",
    "\n",
    "    def _evaluate(self, X_s, X_t):\n",
    "        self.learner.eval()\n",
    "        self.H.eval()\n",
    "        Pr_s = self(self.learner.E(X_s))\n",
    "        Pr_t = self(self.learner.E(X_t))\n",
    "        self.learner.train()\n",
    "        self.H.train()\n",
    "        return 2 * torch.abs(Pr_s.mean() - Pr_t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'divergence': 0.6415772438049316}, {'divergence': 0.5632404088973999})\n",
      "({'divergence': 1.1329022645950317}, {'divergence': 0.9242223501205444})\n",
      "({'divergence': 1.177211046218872}, {'divergence': 0.9128605127334595})\n",
      "({'divergence': 1.34457266330719}, {'divergence': 1.0325337648391724})\n",
      "({'divergence': 1.452427864074707}, {'divergence': 1.0759499073028564})\n",
      "({'divergence': 1.5082886219024658}, {'divergence': 1.092562198638916})\n",
      "({'divergence': 1.570929765701294}, {'divergence': 1.052901268005371})\n",
      "({'divergence': 1.4367001056671143}, {'divergence': 1.0058636665344238})\n",
      "({'divergence': 1.615248203277588}, {'divergence': 1.1351488828659058})\n",
      "({'divergence': 1.424480676651001}, {'divergence': 0.953916072845459})\n",
      "({'divergence': 1.7244157791137695}, {'divergence': 1.0923317670822144})\n",
      "({'divergence': 1.6008427143096924}, {'divergence': 1.0103230476379395})\n",
      "({'divergence': 1.7372565269470215}, {'divergence': 1.1225272417068481})\n",
      "({'divergence': 1.6920890808105469}, {'divergence': 1.0500255823135376})\n",
      "({'divergence': 1.7926368713378906}, {'divergence': 1.1670746803283691})\n",
      "({'divergence': 1.821007490158081}, {'divergence': 1.1965973377227783})\n",
      "({'divergence': 1.7700254917144775}, {'divergence': 1.2217481136322021})\n",
      "({'divergence': 1.8916391134262085}, {'divergence': 1.2265394926071167})\n",
      "({'divergence': 1.9164446592330933}, {'divergence': 1.1845459938049316})\n",
      "({'divergence': 1.801173448562622}, {'divergence': 1.140892744064331})\n",
      "({'divergence': 1.8162765502929688}, {'divergence': 1.1551318168640137})\n",
      "({'divergence': 1.852210283279419}, {'divergence': 1.232408881187439})\n",
      "({'divergence': 1.956745982170105}, {'divergence': 1.1965786218643188})\n",
      "({'divergence': 1.9500460624694824}, {'divergence': 1.193001389503479})\n",
      "({'divergence': 1.9279465675354004}, {'divergence': 1.1748230457305908})\n",
      "({'divergence': 1.8824728727340698}, {'divergence': 1.2833174467086792})\n",
      "({'divergence': 1.931969404220581}, {'divergence': 1.1511205434799194})\n",
      "({'divergence': 1.9683295488357544}, {'divergence': 1.2111321687698364})\n",
      "({'divergence': 1.975812315940857}, {'divergence': 1.258764386177063})\n",
      "({'divergence': 1.9553532600402832}, {'divergence': 1.2403321266174316})\n",
      "({'divergence': 1.8792811632156372}, {'divergence': 1.1210241317749023})\n",
      "({'divergence': 1.9447979927062988}, {'divergence': 1.1807453632354736})\n",
      "({'divergence': 1.9485276937484741}, {'divergence': 1.28965163230896})\n",
      "({'divergence': 1.980623722076416}, {'divergence': 1.2692300081253052})\n",
      "({'divergence': 1.9816921949386597}, {'divergence': 1.299368143081665})\n",
      "({'divergence': 1.8947850465774536}, {'divergence': 1.1686919927597046})\n",
      "({'divergence': 1.9374864101409912}, {'divergence': 1.296046257019043})\n",
      "({'divergence': 1.90597665309906}, {'divergence': 1.139894962310791})\n",
      "({'divergence': 1.7137787342071533}, {'divergence': 1.1209135055541992})\n",
      "({'divergence': 1.988799810409546}, {'divergence': 1.2890846729278564})\n",
      "({'divergence': 1.9906225204467773}, {'divergence': 1.3088207244873047})\n",
      "({'divergence': 1.9892454147338867}, {'divergence': 1.2796757221221924})\n",
      "({'divergence': 1.9863433837890625}, {'divergence': 1.297727346420288})\n",
      "({'divergence': 1.989333987236023}, {'divergence': 1.2950431108474731})\n",
      "({'divergence': 1.988399863243103}, {'divergence': 1.2815515995025635})\n",
      "({'divergence': 1.983728289604187}, {'divergence': 1.292407512664795})\n",
      "({'divergence': 1.9950474500656128}, {'divergence': 1.25417160987854})\n",
      "({'divergence': 1.9537500143051147}, {'divergence': 1.3166654109954834})\n",
      "({'divergence': 1.9927579164505005}, {'divergence': 1.2751445770263672})\n",
      "({'divergence': 1.9951493740081787}, {'divergence': 1.2903236150741577})\n"
     ]
    }
   ],
   "source": [
    "reg = HDivergence(learner, [800]).cuda()\n",
    "reg.find_sup(train_dataset, test_dataset, batch_size=128, valid_split=0.1, num_iterations=5000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divergence': 1.2436727285385132}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.evaluate(source_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
